{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DirectView [0, 1, 2, 3,...]>\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as sio #for the i/o\n",
    "import numpy as np\n",
    "import time #to wait between checking if jobs are done\n",
    "import ipyparallel as ipp\n",
    "\n",
    "rc = ipp.Client()\n",
    "view = rc[:]\n",
    "print(view)\n",
    "procs = np.array(rc.ids) #get list of processors on cluster that local environment can access\n",
    "print(procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Data Directory if not exist\n",
    "datapath = os.path.join(os.getcwd(),\"Data\")\n",
    "os.makedirs(datapath,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "from tensorflow.random import set_seed\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "hid_ls = np.arange(1,11)\n",
    "n_fold = 5\n",
    "\n",
    "#######################################\n",
    "#define the activation function\n",
    "def rbf(x):\n",
    "    return tf.math.exp(-x**2)\n",
    "\n",
    "#######################################\n",
    "#define the derivative of the activation function\n",
    "def d_rbf(x):\n",
    "    return tf.gradients(rbf,x)\n",
    "\n",
    "#######################################\n",
    "#we couldn't use “tf_d_leaky_relu_6” as an activation function if we wanted to \n",
    "#because tensorflow doesn't know how to calculate the gradients of that function.\n",
    "def rbf_grad(op, grad):\n",
    "    x = op.inputs[0]\n",
    "    n_gr = d_rbf(x)    #defining the gradient.\n",
    "    return grad * n_gr\n",
    "\n",
    "def py_func(func, inp, Tout, stateful=True, name=None, grad=None):\n",
    "    # Need to generate a unique name to avoid duplicates:\n",
    "    rnd_name = 'PyFuncGrad' + str(np.random.randint(0, 1E+2))\n",
    "    tf.RegisterGradient(rnd_name)(grad)\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({\"PyFunc\": rnd_name, \"PyFuncStateless\": rnd_name}):\n",
    "#     with g.gradient_override_map({\"PyFunc\": rnd_name}):\n",
    "        return tf.py_func(func, inp, Tout, stateful=stateful, name=name)\n",
    "    \n",
    "def tf_rbf(x,name=None):\n",
    "    with tf.name_scope(name, \"rbf\", [x]) as name:\n",
    "        y = py_func(rbf,   #forward pass function\n",
    "                    [x],\n",
    "                    [tf.float32],\n",
    "                    name=name,\n",
    "                    grad= rbf_grad) #the function that overrides gradient\n",
    "        y[0].set_shape(x.get_shape())     #when using with the code, it is used to specify the rank of the input.\n",
    "    return y[0]\n",
    "\n",
    "\n",
    "def func(proc_num, proc_max):\n",
    "    \n",
    "    def func(X,y,n_fold,n_hid,n_epo,seed=12345):\n",
    "        '''\n",
    "        return the average of weighted error for `n_fold` splits\n",
    "        '''\n",
    "        train_score = []\n",
    "        test_score = []\n",
    "        set_seed(seed)\n",
    "        kf = KFold(n_splits=n_fold)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            model = tf.keras.Sequential()\n",
    "            model.add(tf.keras.layers.Dense(n_hid,activation=rbf,input_dim=1))  #hid2\n",
    "            model.add(tf.keras.layers.Dense(1))\n",
    "            model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "            model.fit(X_train,y_train, epochs=n_epo, verbose=0)\n",
    "\n",
    "            error_train = tf.keras.losses.MSE(model.predict(X_train).flatten(),y_train).numpy()\n",
    "            error_test = tf.keras.losses.MSE(model.predict(X_test).flatten(),y_test).numpy()\n",
    "    #         error_ave = (error_train + error_test*(n_fold-1))/n_fold   #weighted average\n",
    "            train_score.append(error_train)\n",
    "            test_score.append(error_test)\n",
    "        return np.mean(train_score), np.mean(test_score)\n",
    "    \n",
    "    i = proc_num  #range from 0 to len(hid_ls)\n",
    "    score = [func(X,y,n_fold,hid_ls[i],j) for j in epo_ls]  \n",
    "    train = [score[i][0] for i in range(len(score))]\n",
    "    test = [score[i][1] for i in range(len(score))]\n",
    "    filename = '/home/jovyan/work/Thesis_Wenjuan_Code/Data/%s_1%s1_split_MSE.mat'%(st_name,hid_ls[i]) #1_x2_1%s1\n",
    "#     datapath = os.path.join(os.getcwd(),\"Data\")\n",
    "#     os.makedirs(datapath,exist_ok=True)\n",
    "#     filename = 'Data/%s_1%s1_split_MSE0.mat'%(st_name,hid_ls[i]) #1_x2_1%s1\n",
    "    data_dict = {'train':train, 'test':test}\n",
    "    sio.savemat(filename, data_dict)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "$$\n",
    "y = \\sin x\n",
    "$$\n",
    "\n",
    "Sample size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "epo_ls = 10*np.arange(1,11)\n",
    "np.random.seed(12345)\n",
    "X = np.pi*np.random.uniform(-1,1,size=1000)\n",
    "y = np.sin(X)\n",
    "st_name = \"sin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.push(dict(procs=procs)) #This pushes procs to all processors on the cluster\n",
    "\n",
    "async_process = view.map_async(lambda proc_num: func(proc_num, proc_max=procs.size), range(procs.size) ) \n",
    "\n",
    "time.sleep(1) #give the process time to start and see if any errors occur\n",
    "if async_process.error[0] is None:\n",
    "    done = False    \n",
    "    while done == False:\n",
    "        if async_process.done():\n",
    "            done = True\n",
    "            #print('Now we can load in the data')\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(async_process.error[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "$$\n",
    "y = \\sin x\n",
    "$$\n",
    "Sample size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "epo_ls = 10*np.arange(1,11)\n",
    "np.random.seed(12345)\n",
    "X = np.pi*np.random.uniform(-1,1,size=5000)\n",
    "y = np.sin(X)\n",
    "st_name = \"sin5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.push(dict(procs=procs)) #This pushes procs to all processors on the cluster\n",
    "\n",
    "async_process = view.map_async(lambda proc_num: func(proc_num, proc_max=procs.size), range(procs.size) ) \n",
    "\n",
    "time.sleep(1) #give the process time to start and see if any errors occur\n",
    "if async_process.error[0] is None:\n",
    "    done = False    \n",
    "    while done == False:\n",
    "        if async_process.done():\n",
    "            done = True\n",
    "            #print('Now we can load in the data')\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(async_process.error[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "\n",
    "$$\n",
    "y=(x+3)(x-1)^2\n",
    "$$\n",
    "Sample size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "epo_ls = 100*np.arange(1,11)\n",
    "np.random.seed(12345)\n",
    "X = np.random.uniform(-3,3,size=1000)\n",
    "y = (X+3)*(X-1)**2\n",
    "st_name = \"poly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.push(dict(procs=procs)) #This pushes procs to all processors on the cluster\n",
    "\n",
    "async_process = view.map_async(lambda proc_num: func(proc_num, proc_max=procs.size), range(procs.size) ) \n",
    "\n",
    "time.sleep(1) #give the process time to start and see if any errors occur\n",
    "if async_process.error[0] is None:\n",
    "    done = False    \n",
    "    while done == False:\n",
    "        if async_process.done():\n",
    "            done = True\n",
    "            #print('Now we can load in the data')\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(async_process.error[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "\n",
    "$$\n",
    "y=(x+3)(x-1)^2\n",
    "$$\n",
    "Sample size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "epo_ls = 100*np.arange(1,11)\n",
    "np.random.seed(12345)\n",
    "X = np.random.uniform(-3,3,size=5000)\n",
    "y = (X+3)*(X-1)**2\n",
    "st_name = \"poly5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.push(dict(procs=procs)) #This pushes procs to all processors on the cluster\n",
    "\n",
    "async_process = view.map_async(lambda proc_num: func(proc_num, proc_max=procs.size), range(procs.size) ) \n",
    "\n",
    "time.sleep(1) #give the process time to start and see if any errors occur\n",
    "if async_process.error[0] is None:\n",
    "    done = False    \n",
    "    while done == False:\n",
    "        if async_process.done():\n",
    "            done = True\n",
    "            #print('Now we can load in the data')\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(async_process.error[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
